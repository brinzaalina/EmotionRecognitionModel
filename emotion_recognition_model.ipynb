{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Load data from the data set into test, training and validation sets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset information: \n",
      "Training data: (16000, 2)\n",
      "Validation data: (2000, 2)\n",
      "Test data: (2000, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "test = pd.read_csv(\"datasets/test.csv\")\n",
    "training = pd.read_csv(\"datasets/training.csv\")\n",
    "validation = pd.read_csv(\"datasets/validation.csv\")\n",
    "\n",
    "print(\"Dataset information: \")\n",
    "print(f'Training data: {training.shape}')\n",
    "print(f'Validation data: {validation.shape}')\n",
    "print(f'Test data: {test.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T18:38:13.840981100Z",
     "start_time": "2023-06-13T18:38:09.376195900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load tokenizer, model and create functions needed to process text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import contractions\n",
    "\n",
    "# Load BERT model and tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-cased')\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # remove links\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
    "    # remove words like href, img, www, http, width, height, src\n",
    "    text = re.sub(r\"\\S*(href|img|www|http|width|height|src)\\S*\", \"\", text)\n",
    "    # remove contractions\n",
    "    text = contractions.fix(text)\n",
    "    # remove special characters\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    encoded_input = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=False,\n",
    "        max_length=512,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    return encoded_input['input_ids'], encoded_input['attention_mask']\n",
    "\n",
    "def extract_features(inputs, masks):\n",
    "    print('Extract features' + ' - ' + str(datetime.now()))\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs, attention_mask=masks)\n",
    "        pooled_output = outputs[0][:, 0, :]\n",
    "    print('Finish extract features' + ' - ' + str(datetime.now()))\n",
    "    return pooled_output.numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-06-13T18:38:17.431727600Z",
     "start_time": "2023-06-13T18:38:13.845983700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Perform batch text preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin preprocess batch 0 - 2023-06-13 21:38:17.440726\n",
      "Begin preprocess text in batch 0 - 2023-06-13 21:38:17.441725\n",
      "Extract features - 2023-06-13 21:38:17.917765\n",
      "Finish extract features - 2023-06-13 21:42:46.756882\n",
      "Finish preprocess batch 0 - 2023-06-13 21:42:46.757882\n",
      "Begin preprocess batch 1 - 2023-06-13 21:42:46.757882\n",
      "Begin preprocess text in batch 1 - 2023-06-13 21:42:46.758882\n",
      "Extract features - 2023-06-13 21:42:47.098889\n",
      "Finish extract features - 2023-06-13 21:47:08.796492\n",
      "Finish preprocess batch 1 - 2023-06-13 21:47:08.797451\n",
      "Begin preprocess batch 2 - 2023-06-13 21:47:08.797451\n",
      "Begin preprocess text in batch 2 - 2023-06-13 21:47:08.797451\n",
      "Extract features - 2023-06-13 21:47:09.174459\n",
      "Finish extract features - 2023-06-13 21:51:28.219486\n",
      "Finish preprocess batch 2 - 2023-06-13 21:51:28.220487\n",
      "Begin preprocess batch 3 - 2023-06-13 21:51:28.220487\n",
      "Begin preprocess text in batch 3 - 2023-06-13 21:51:28.221486\n",
      "Extract features - 2023-06-13 21:51:28.591487\n",
      "Finish extract features - 2023-06-13 21:55:49.769533\n",
      "Finish preprocess batch 3 - 2023-06-13 21:55:49.770532\n",
      "Begin preprocess batch 4 - 2023-06-13 21:55:49.770532\n",
      "Begin preprocess text in batch 4 - 2023-06-13 21:55:49.771532\n",
      "Extract features - 2023-06-13 21:55:50.100537\n",
      "Finish extract features - 2023-06-13 22:00:07.752579\n",
      "Finish preprocess batch 4 - 2023-06-13 22:00:07.752579\n",
      "Begin preprocess batch 5 - 2023-06-13 22:00:07.752579\n",
      "Begin preprocess text in batch 5 - 2023-06-13 22:00:07.753579\n",
      "Extract features - 2023-06-13 22:00:08.097620\n",
      "Finish extract features - 2023-06-13 22:04:27.704094\n",
      "Finish preprocess batch 5 - 2023-06-13 22:04:27.705096\n",
      "Begin preprocess batch 6 - 2023-06-13 22:04:27.705096\n",
      "Begin preprocess text in batch 6 - 2023-06-13 22:04:27.706093\n",
      "Extract features - 2023-06-13 22:04:28.055095\n",
      "Finish extract features - 2023-06-13 22:08:45.390705\n",
      "Finish preprocess batch 6 - 2023-06-13 22:08:45.390705\n",
      "Begin preprocess batch 7 - 2023-06-13 22:08:45.390705\n",
      "Begin preprocess text in batch 7 - 2023-06-13 22:08:45.392694\n",
      "Extract features - 2023-06-13 22:08:45.763657\n",
      "Finish extract features - 2023-06-13 22:13:02.121692\n",
      "Finish preprocess batch 7 - 2023-06-13 22:13:02.122692\n",
      "Begin preprocess batch 8 - 2023-06-13 22:13:02.122692\n",
      "Begin preprocess text in batch 8 - 2023-06-13 22:13:02.123692\n",
      "Extract features - 2023-06-13 22:13:02.480735\n",
      "Finish extract features - 2023-06-13 22:17:27.623733\n",
      "Finish preprocess batch 8 - 2023-06-13 22:17:27.624734\n",
      "Begin preprocess batch 9 - 2023-06-13 22:17:27.624734\n",
      "Begin preprocess text in batch 9 - 2023-06-13 22:17:27.625733\n",
      "Extract features - 2023-06-13 22:17:28.046736\n",
      "Finish extract features - 2023-06-13 22:21:54.372788\n",
      "Finish preprocess batch 9 - 2023-06-13 22:21:54.373824\n",
      "Begin preprocess batch 10 - 2023-06-13 22:21:54.373824\n",
      "Begin preprocess text in batch 10 - 2023-06-13 22:21:54.374830\n",
      "Extract features - 2023-06-13 22:21:54.724795\n",
      "Finish extract features - 2023-06-13 22:26:28.282326\n",
      "Finish preprocess batch 10 - 2023-06-13 22:26:28.283327\n",
      "Begin preprocess batch 11 - 2023-06-13 22:26:28.283327\n",
      "Begin preprocess text in batch 11 - 2023-06-13 22:26:28.284327\n",
      "Extract features - 2023-06-13 22:26:28.642326\n",
      "Finish extract features - 2023-06-13 22:30:56.890402\n",
      "Finish preprocess batch 11 - 2023-06-13 22:30:56.891401\n",
      "Begin preprocess batch 12 - 2023-06-13 22:30:56.891401\n",
      "Begin preprocess text in batch 12 - 2023-06-13 22:30:56.892402\n",
      "Extract features - 2023-06-13 22:30:57.242359\n",
      "Finish extract features - 2023-06-13 22:35:25.355403\n",
      "Finish preprocess batch 12 - 2023-06-13 22:35:25.356363\n",
      "Begin preprocess batch 13 - 2023-06-13 22:35:25.356363\n",
      "Begin preprocess text in batch 13 - 2023-06-13 22:35:25.357361\n",
      "Extract features - 2023-06-13 22:35:25.717359\n",
      "Finish extract features - 2023-06-13 22:39:51.539939\n",
      "Finish preprocess batch 13 - 2023-06-13 22:39:51.539939\n",
      "Begin preprocess batch 14 - 2023-06-13 22:39:51.539939\n",
      "Begin preprocess text in batch 14 - 2023-06-13 22:39:51.543939\n",
      "Extract features - 2023-06-13 22:39:51.896101\n",
      "Finish extract features - 2023-06-13 22:44:09.771136\n",
      "Finish preprocess batch 14 - 2023-06-13 22:44:09.771136\n",
      "Begin preprocess batch 15 - 2023-06-13 22:44:09.771136\n",
      "Begin preprocess text in batch 15 - 2023-06-13 22:44:09.774137\n",
      "Extract features - 2023-06-13 22:44:10.122140\n",
      "Finish extract features - 2023-06-13 22:48:33.438826\n",
      "Finish preprocess batch 15 - 2023-06-13 22:48:33.439786\n",
      "Begin preprocess batch 16 - 2023-06-13 22:48:33.439786\n",
      "Begin preprocess text in batch 16 - 2023-06-13 22:48:33.440787\n",
      "Extract features - 2023-06-13 22:48:33.795821\n",
      "Finish extract features - 2023-06-13 22:52:54.272398\n",
      "Finish preprocess batch 16 - 2023-06-13 22:52:54.273397\n",
      "Begin preprocess batch 17 - 2023-06-13 22:52:54.273397\n",
      "Begin preprocess text in batch 17 - 2023-06-13 22:52:54.274398\n",
      "Extract features - 2023-06-13 22:52:54.646397\n",
      "Finish extract features - 2023-06-13 22:57:11.832958\n",
      "Finish preprocess batch 17 - 2023-06-13 22:57:11.833959\n",
      "Begin preprocess batch 18 - 2023-06-13 22:57:11.833959\n",
      "Begin preprocess text in batch 18 - 2023-06-13 22:57:11.833959\n",
      "Extract features - 2023-06-13 22:57:12.198954\n",
      "Finish extract features - 2023-06-13 23:01:27.237041\n",
      "Finish preprocess batch 18 - 2023-06-13 23:01:27.237041\n",
      "Begin preprocess batch 19 - 2023-06-13 23:01:27.237041\n",
      "Begin preprocess text in batch 19 - 2023-06-13 23:01:27.239041\n",
      "Extract features - 2023-06-13 23:01:27.605046\n",
      "Finish extract features - 2023-06-13 23:05:47.680225\n",
      "Finish preprocess batch 19 - 2023-06-13 23:05:47.680225\n",
      "Begin preprocess batch 20 - 2023-06-13 23:05:47.680225\n",
      "Begin preprocess text in batch 20 - 2023-06-13 23:05:47.682224\n",
      "Extract features - 2023-06-13 23:05:48.024229\n",
      "Finish extract features - 2023-06-13 23:10:11.924313\n",
      "Finish preprocess batch 20 - 2023-06-13 23:10:11.924313\n",
      "Begin preprocess batch 21 - 2023-06-13 23:10:11.924313\n",
      "Begin preprocess text in batch 21 - 2023-06-13 23:10:11.926274\n",
      "Extract features - 2023-06-13 23:10:12.284310\n",
      "Finish extract features - 2023-06-13 23:14:32.501381\n",
      "Finish preprocess batch 21 - 2023-06-13 23:14:32.501381\n",
      "Begin preprocess batch 22 - 2023-06-13 23:14:32.501381\n",
      "Begin preprocess text in batch 22 - 2023-06-13 23:14:32.505381\n",
      "Extract features - 2023-06-13 23:14:32.855423\n",
      "Finish extract features - 2023-06-13 23:18:53.633449\n",
      "Finish preprocess batch 22 - 2023-06-13 23:18:53.634448\n",
      "Begin preprocess batch 23 - 2023-06-13 23:18:53.634448\n",
      "Begin preprocess text in batch 23 - 2023-06-13 23:18:53.635449\n",
      "Extract features - 2023-06-13 23:18:53.984452\n",
      "Finish extract features - 2023-06-13 23:23:19.650488\n",
      "Finish preprocess batch 23 - 2023-06-13 23:23:19.650488\n",
      "Begin preprocess batch 24 - 2023-06-13 23:23:19.650488\n",
      "Begin preprocess text in batch 24 - 2023-06-13 23:23:19.651488\n",
      "Extract features - 2023-06-13 23:23:19.990517\n",
      "Finish extract features - 2023-06-13 23:27:44.198601\n",
      "Finish preprocess batch 24 - 2023-06-13 23:27:44.199601\n",
      "Begin preprocess batch 25 - 2023-06-13 23:27:44.199601\n",
      "Begin preprocess text in batch 25 - 2023-06-13 23:27:44.200601\n",
      "Extract features - 2023-06-13 23:27:44.591606\n",
      "Finish extract features - 2023-06-13 23:32:08.452782\n",
      "Finish preprocess batch 25 - 2023-06-13 23:32:08.452782\n",
      "Begin preprocess batch 26 - 2023-06-13 23:32:08.452782\n",
      "Begin preprocess text in batch 26 - 2023-06-13 23:32:08.453727\n",
      "Extract features - 2023-06-13 23:32:08.801762\n",
      "Finish extract features - 2023-06-13 23:36:37.351282\n",
      "Finish preprocess batch 26 - 2023-06-13 23:36:37.351282\n",
      "Begin preprocess batch 27 - 2023-06-13 23:36:37.351282\n",
      "Begin preprocess text in batch 27 - 2023-06-13 23:36:37.352283\n",
      "Extract features - 2023-06-13 23:36:37.694333\n",
      "Finish extract features - 2023-06-13 23:41:16.382523\n",
      "Finish preprocess batch 27 - 2023-06-13 23:41:16.382523\n",
      "Begin preprocess batch 28 - 2023-06-13 23:41:16.382523\n",
      "Begin preprocess text in batch 28 - 2023-06-13 23:41:16.384522\n",
      "Extract features - 2023-06-13 23:41:16.738489\n",
      "Finish extract features - 2023-06-13 23:46:16.476895\n",
      "Finish preprocess batch 28 - 2023-06-13 23:46:16.476895\n",
      "Begin preprocess batch 29 - 2023-06-13 23:46:16.476895\n",
      "Begin preprocess text in batch 29 - 2023-06-13 23:46:16.477893\n",
      "Extract features - 2023-06-13 23:46:16.843928\n",
      "Finish extract features - 2023-06-13 23:50:54.010512\n",
      "Finish preprocess batch 29 - 2023-06-13 23:50:54.011552\n",
      "Begin preprocess batch 30 - 2023-06-13 23:50:54.011552\n",
      "Begin preprocess text in batch 30 - 2023-06-13 23:50:54.011552\n",
      "Extract features - 2023-06-13 23:50:54.412514\n",
      "Finish extract features - 2023-06-13 23:55:25.623035\n",
      "Finish preprocess batch 30 - 2023-06-13 23:55:25.623035\n",
      "Begin preprocess batch 31 - 2023-06-13 23:55:25.623035\n",
      "Begin preprocess text in batch 31 - 2023-06-13 23:55:25.626040\n",
      "Extract features - 2023-06-13 23:55:25.984028\n",
      "Finish extract features - 2023-06-14 00:00:02.387653\n",
      "Finish preprocess batch 31 - 2023-06-14 00:00:02.387653\n"
     ]
    }
   ],
   "source": [
    "# Preprocess training dataset\n",
    "batch_size = 500\n",
    "num_batches = len(training) // batch_size\n",
    "training_features = []\n",
    "for i in range(num_batches):\n",
    "    print('Begin preprocess batch ' + str(i) + ' - ' + str(datetime.now()))\n",
    "    # Get the current batch\n",
    "    batch_data = training[i * batch_size : (i + 1) * batch_size]['text']\n",
    "    batch_labels = training[i * batch_size : (i + 1) * batch_size]['label']\n",
    "\n",
    "    # Preprocess the input text using DistilBERT for the current batch\n",
    "    batch_inputs = []\n",
    "    batch_masks = []\n",
    "    print('Begin preprocess text in batch ' + str(i) + ' - ' + str(datetime.now()))\n",
    "    for text in batch_data:\n",
    "        input_ids, attention_mask = preprocess_text(text)\n",
    "        batch_inputs.append(input_ids)\n",
    "        batch_masks.append(attention_mask)\n",
    "\n",
    "    batch_inputs = torch.cat(batch_inputs, dim=0)\n",
    "    batch_masks = torch.cat(batch_masks, dim=0)\n",
    "\n",
    "    pooled_output = extract_features(batch_inputs, batch_masks)\n",
    "    training_features.append(pooled_output)\n",
    "    print('Finish preprocess batch ' + str(i) + ' - ' + str(datetime.now()))\n",
    "# obtain final features and labels\n",
    "training_features = np.concatenate(training_features, axis=0)\n",
    "training_labels = training['label'].values[:training_features.shape[0]]\n",
    "\n",
    "# save the features and labels\n",
    "np.save('models/training_features-3.npy', training_features)\n",
    "np.save('models/training_labels-3.npy', training_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T21:00:11.637995400Z",
     "start_time": "2023-06-13T18:38:17.440726900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before oversampling:  [4666 5362 1304 2159 1937  572]\n"
     ]
    }
   ],
   "source": [
    "# Oversample those classes that have less than 1000 samples to a total of half of the majority class using sklearn\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# load the training features and labels\n",
    "training_features = np.load('models/training_features-3.npy')\n",
    "training_labels = np.load('models/training_labels-3.npy')\n",
    "\n",
    "# compute the class distribution\n",
    "class_distribution = np.bincount(training_labels)\n",
    "print('Class distribution before oversampling: ', class_distribution)\n",
    "\n",
    "# oversample the minority classes; if the class is not a minority class, then do not oversample it and keep it as it is\n",
    "oversampled_features = []\n",
    "oversampled_labels = []\n",
    "\n",
    "majority_class_count = np.max(class_distribution)\n",
    "\n",
    "for label in np.unique(training_labels):\n",
    "    if class_distribution[label] < majority_class_count // 2:\n",
    "        # oversample the minority class\n",
    "        class_indices = np.where(training_labels == label)[0]\n",
    "        oversampled_class_indices = resample(class_indices, replace=True, n_samples=majority_class_count // 2, random_state=0)\n",
    "\n",
    "        oversampled_features.append(training_features[oversampled_class_indices])\n",
    "        oversampled_labels.append(training_labels[oversampled_class_indices])\n",
    "    else:\n",
    "        # keep the majority class as it is\n",
    "        majority_features = training_features[training_labels == label]\n",
    "        majority_labels = training_labels[training_labels == label]\n",
    "\n",
    "        # append the majority class to the list of oversampled features and labels\n",
    "        oversampled_features.append(majority_features)\n",
    "        oversampled_labels.append(majority_labels)\n",
    "\n",
    "# obtain final features and labels\n",
    "oversampled_features = np.concatenate(oversampled_features, axis=0)\n",
    "oversampled_labels = np.concatenate(oversampled_labels, axis=0)\n",
    "\n",
    "# save the features and labels\n",
    "np.save('models/training_features-3-over.npy', oversampled_features)\n",
    "np.save('models/training_labels-3-over.npy', oversampled_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T21:00:15.764488700Z",
     "start_time": "2023-06-13T21:00:11.696045100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Choose a suitable subset of the training data to find the best parameters for the SVM model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution of the entire training set:  [4666 5362 2681 2681 2681 2681]\n",
      "Class distribution of the subset:  [1388 1641  794  750  829  823]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# load the training features and labels\n",
    "training_features = np.load('models/training_features-3-over.npy')\n",
    "training_labels = np.load('models/training_labels-3-over.npy')\n",
    "\n",
    "subset_size = 0.3\n",
    "# split the training data into a subset and the remaining data\n",
    "subset_indices = np.random.choice(len(training_features), int(subset_size * len(training_features)), replace=False)\n",
    "subset_features = training_features[subset_indices]\n",
    "\n",
    "# compute the class distribution of the subset\n",
    "subset_labels = training_labels[subset_indices]\n",
    "subset_class_distribution = np.bincount(subset_labels)\n",
    "\n",
    "# compute the class distribution of the entire training set\n",
    "training_class_distribution = np.bincount(training_labels)\n",
    "\n",
    "# compare the class distributions\n",
    "print('Class distribution of the entire training set: ', training_class_distribution)\n",
    "print('Class distribution of the subset: ', subset_class_distribution)\n",
    "\n",
    "# visualize plots of the class distributions\n",
    "import matplotlib.pyplot as plt\n",
    "plt.bar(np.arange(len(training_class_distribution)), training_class_distribution, label='Training set')\n",
    "plt.bar(np.arange(len(subset_class_distribution)), subset_class_distribution, label='Subset')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T21:00:18.112660300Z",
     "start_time": "2023-06-13T21:00:15.770453500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Perform grid search to find the best parameters for the SVM model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin grid search - 2023-06-14 00:00:18.106661\n",
      "Training SVM to find the best hyperparameters - 2023-06-14 00:00:18.107655\n",
      "Finished looking for best hyperparameters - 2023-06-14 00:26:21.913114\n",
      "Best hyperparameters:  {'C': 75, 'gamma': 0.01, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# SVM classification\n",
    "parameters = {\n",
    "    'C': [ 1, 50, 75, 90],\n",
    "    'gamma': [1, 0.01, 0.001 , 'scale'],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "# Construct the final SVM\n",
    "final_svm_classifier = SVC(class_weight='balanced')\n",
    "# Perform grid search to find the best parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "print('Begin grid search' + ' - ' + str(datetime.now()))\n",
    "grid_search = GridSearchCV(final_svm_classifier, parameters, cv=5)\n",
    "print('Training SVM to find the best hyperparameters' + ' - ' + str(datetime.now()))\n",
    "grid_search.fit(subset_features, subset_labels)\n",
    "print('Finished looking for best hyperparameters' + ' - ' + str(datetime.now()))\n",
    "print('Best hyperparameters: ', grid_search.best_params_)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T21:26:21.920410700Z",
     "start_time": "2023-06-13T21:00:18.107655400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train the final SVM model with the best parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training final SVM model - 2023-06-14 00:26:21.921409\n",
      "Finished training final SVM model - 2023-06-14 00:30:04.001030\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "# Use the best model for prediction\n",
    "final_svm_classifier = grid_search.best_estimator_\n",
    "# use the already existing model\n",
    "print('Begin training final SVM model' + ' - ' + str(datetime.now()))\n",
    "final_svm_classifier.fit(training_features, training_labels)\n",
    "print('Finished training final SVM model' + ' - ' + str(datetime.now()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T21:30:04.007572500Z",
     "start_time": "2023-06-13T21:26:21.927406Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save the generated model for later use"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "['models/model-7-over.pkl']"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save generated SVM model\n",
    "import joblib\n",
    "joblib.dump(final_svm_classifier, 'models/model-7-over.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-06-13T21:30:04.087653800Z",
     "start_time": "2023-06-13T21:30:04.008573Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Process test data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin processing for test batch 0 - 2023-06-14 00:30:04.091654\n",
      "0\n",
      "Extract features - 2023-06-14 00:30:04.244649\n",
      "Finish extract features - 2023-06-14 00:31:48.648705\n",
      "End processing for test batch 0 - 2023-06-14 00:31:48.686704\n",
      "Begin processing for test batch 1 - 2023-06-14 00:31:48.686704\n",
      "1\n",
      "Extract features - 2023-06-14 00:31:48.826702\n",
      "Finish extract features - 2023-06-14 00:33:36.535275\n",
      "End processing for test batch 1 - 2023-06-14 00:33:36.535275\n",
      "Begin processing for test batch 2 - 2023-06-14 00:33:36.535275\n",
      "2\n",
      "Extract features - 2023-06-14 00:33:36.705311\n",
      "Finish extract features - 2023-06-14 00:35:19.785276\n",
      "End processing for test batch 2 - 2023-06-14 00:35:19.786275\n",
      "Begin processing for test batch 3 - 2023-06-14 00:35:19.786275\n",
      "3\n",
      "Extract features - 2023-06-14 00:35:19.963282\n",
      "Finish extract features - 2023-06-14 00:37:15.829324\n",
      "End processing for test batch 3 - 2023-06-14 00:37:15.830323\n",
      "Begin processing for test batch 4 - 2023-06-14 00:37:15.830323\n",
      "4\n",
      "Extract features - 2023-06-14 00:37:16.000325\n",
      "Finish extract features - 2023-06-14 00:39:18.316846\n",
      "End processing for test batch 4 - 2023-06-14 00:39:18.316846\n",
      "Begin processing for test batch 5 - 2023-06-14 00:39:18.316846\n",
      "5\n",
      "Extract features - 2023-06-14 00:39:18.488848\n",
      "Finish extract features - 2023-06-14 00:41:21.851360\n",
      "End processing for test batch 5 - 2023-06-14 00:41:21.851360\n",
      "Begin processing for test batch 6 - 2023-06-14 00:41:21.852364\n",
      "6\n",
      "Extract features - 2023-06-14 00:41:22.023360\n",
      "Finish extract features - 2023-06-14 00:43:18.317518\n",
      "End processing for test batch 6 - 2023-06-14 00:43:18.318518\n",
      "Begin processing for test batch 7 - 2023-06-14 00:43:18.318518\n",
      "7\n",
      "Extract features - 2023-06-14 00:43:18.489518\n",
      "Finish extract features - 2023-06-14 00:45:15.465521\n",
      "End processing for test batch 7 - 2023-06-14 00:45:15.466521\n",
      "Begin processing for test batch 8 - 2023-06-14 00:45:15.466521\n",
      "8\n",
      "Extract features - 2023-06-14 00:45:15.619558\n",
      "Finish extract features - 2023-06-14 00:47:11.672116\n",
      "End processing for test batch 8 - 2023-06-14 00:47:11.673116\n",
      "Begin processing for test batch 9 - 2023-06-14 00:47:11.673116\n",
      "9\n",
      "Extract features - 2023-06-14 00:47:11.850123\n",
      "Finish extract features - 2023-06-14 00:49:06.930587\n",
      "End processing for test batch 9 - 2023-06-14 00:49:06.931589\n"
     ]
    }
   ],
   "source": [
    "test_labels = []\n",
    "test_features = []\n",
    "# Extract features for test dataset\n",
    "test_batch_size = 200\n",
    "num_batches = len(test) // test_batch_size\n",
    "\n",
    "for i in range(num_batches):\n",
    "    print('Begin processing for test batch ' + str(i) + ' - ' + str(datetime.now()))\n",
    "    test_batch_data = test[i * test_batch_size : (i + 1) * test_batch_size]['text']\n",
    "    test_batch_labels = test[i * test_batch_size : (i + 1) * test_batch_size]['label']\n",
    "    test_labels.extend(test_batch_labels)\n",
    "    test_batch_inputs = []\n",
    "    test_batch_masks = []\n",
    "    for text in test_batch_data:\n",
    "        input_ids, attention_mask = preprocess_text(text)\n",
    "        test_batch_inputs.append(input_ids)\n",
    "        test_batch_masks.append(attention_mask)\n",
    "    test_batch_inputs = torch.cat(test_batch_inputs, dim=0)\n",
    "    test_batch_masks = torch.cat(test_batch_masks, dim=0)\n",
    "    print(i)\n",
    "    pooled_output = extract_features(test_batch_inputs, test_batch_masks)\n",
    "    test_features.append(pooled_output)\n",
    "    print('End processing for test batch ' + str(i) + ' - ' + str(datetime.now()))\n",
    "\n",
    "test_labels = torch.tensor(test_labels)\n",
    "all_test_features = np.concatenate(test_features, axis=0)\n",
    "\n",
    "# save the extracted test features and test labels for later use\n",
    "np.save('models/test_features-3.npy', all_test_features)\n",
    "np.save('models/test_labels-3.npy', test_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-06-13T21:49:06.953368Z",
     "start_time": "2023-06-13T21:30:04.091654100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before oversampling:  [581 695 159 275 224  66]\n"
     ]
    }
   ],
   "source": [
    "# Oversample those classes that have less than half samples to a total of half of the majority class using sklearn\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# load the training features and labels\n",
    "test_features = np.load('models/test_features-3.npy')\n",
    "test_labels = np.load('models/test_labels-3.npy')\n",
    "\n",
    "# compute the class distribution\n",
    "class_distribution = np.bincount(test_labels)\n",
    "print('Class distribution before oversampling: ', class_distribution)\n",
    "\n",
    "# oversample the minority classes; if the class is not a minority class, then do not oversample it and keep it as it is\n",
    "oversampled_features = []\n",
    "oversampled_labels = []\n",
    "\n",
    "majority_class_count = np.max(class_distribution)\n",
    "\n",
    "for label in np.unique(training_labels):\n",
    "    if class_distribution[label] < majority_class_count // 2:\n",
    "        # oversample the minority class\n",
    "        class_indices = np.where(training_labels == label)[0]\n",
    "        oversampled_class_indices = resample(class_indices, replace=True, n_samples=majority_class_count // 2, random_state=0)\n",
    "\n",
    "        oversampled_features.append(training_features[oversampled_class_indices])\n",
    "        oversampled_labels.append(training_labels[oversampled_class_indices])\n",
    "    else:\n",
    "        # keep the majority class as it is\n",
    "        majority_features = test_features[test_labels == label]\n",
    "        majority_labels = test_labels[test_labels == label]\n",
    "\n",
    "        # append the majority class to the list of oversampled features and labels\n",
    "        oversampled_features.append(majority_features)\n",
    "        oversampled_labels.append(majority_labels)\n",
    "\n",
    "# obtain final features and labels\n",
    "oversampled_features = np.concatenate(oversampled_features, axis=0)\n",
    "oversampled_labels = np.concatenate(oversampled_labels, axis=0)\n",
    "\n",
    "# save the features and labels\n",
    "np.save('models/test_features-3-over.npy', oversampled_features)\n",
    "np.save('models/test_labels-3-over.npy', oversampled_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T21:49:07.181897Z",
     "start_time": "2023-06-13T21:49:06.968367600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Predict for the test set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin prediction - 2023-06-14 00:49:07.220895\n",
      "Finish prediction - 2023-06-14 00:49:44.867409\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.71      0.77       581\n",
      "           1       0.86      0.75      0.80       695\n",
      "           2       0.85      1.00      0.92       347\n",
      "           3       0.85      1.00      0.92       347\n",
      "           4       0.89      0.99      0.94       347\n",
      "           5       0.96      1.00      0.98       347\n",
      "\n",
      "    accuracy                           0.87      2664\n",
      "   macro avg       0.87      0.91      0.89      2664\n",
      "weighted avg       0.87      0.87      0.87      2664\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# load the test features and labels\n",
    "all_test_features = np.load('models/test_features-3-over.npy')\n",
    "test_labels = np.load('models/test_labels-3-over.npy')\n",
    "print('Begin prediction' + ' - ' + str(datetime.now()))\n",
    "loaded_svm_classifier = joblib.load('models/model-7-over.pkl')\n",
    "predictions = loaded_svm_classifier.predict(all_test_features)\n",
    "print('Finish prediction' + ' - ' + str(datetime.now()))\n",
    "report = classification_report(test_labels, predictions)\n",
    "print(report)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-06-13T21:49:44.889585500Z",
     "start_time": "2023-06-13T21:49:07.190895Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract features - 2023-06-14 01:42:13.747668\n",
      "Finish extract features - 2023-06-14 01:42:14.569670\n",
      "Prediction:  [0]\n"
     ]
    }
   ],
   "source": [
    "test_case1 = 'i do feel completely isolated'\n",
    "loaded_svm_classifier = joblib.load('models/model-7-over.pkl')\n",
    "input_ids, attention_mask = preprocess_text(test_case1)\n",
    "test_features = extract_features(input_ids, attention_mask)\n",
    "prediction = loaded_svm_classifier.predict(test_features)\n",
    "print(\"Prediction: \", prediction)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-06-13T22:42:14.600385600Z",
     "start_time": "2023-06-13T22:42:13.655670400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin prediction - 2023-06-14 02:23:07.805972\n",
      "Finish prediction - 2023-06-14 02:28:40.461785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      4666\n",
      "           1       1.00      0.99      0.99      5362\n",
      "           2       0.99      1.00      1.00      2681\n",
      "           3       1.00      1.00      1.00      2681\n",
      "           4       1.00      1.00      1.00      2681\n",
      "           5       1.00      1.00      1.00      2681\n",
      "\n",
      "    accuracy                           0.99     20752\n",
      "   macro avg       0.99      1.00      1.00     20752\n",
      "weighted avg       0.99      0.99      0.99     20752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict for the training set\n",
    "all_training_features = np.load('models/training_features-3-over.npy')\n",
    "training_labels = np.load('models/training_labels-3-over.npy')\n",
    "print('Begin prediction' + ' - ' + str(datetime.now()))\n",
    "loaded_svm_classifier = joblib.load('models/model-7-over.pkl')\n",
    "predictions = loaded_svm_classifier.predict(all_training_features)\n",
    "print('Finish prediction' + ' - ' + str(datetime.now()))\n",
    "report = classification_report(training_labels, predictions)\n",
    "print(report)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T23:28:40.495886700Z",
     "start_time": "2023-06-13T23:23:07.787972400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
